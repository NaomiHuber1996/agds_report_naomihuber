---
title: "agds_report_8"
author: "Naomi Huber"
date: "2023-04-22"
output: html_document
---

#Einlesen der Daten
```{r}
library(utils)
library(tidyverse)
website <- "https://raw.githubusercontent.com/geco-bern/agds/main/data/df_for_stepwise_regression.csv"
daten <- read.table(website, header = TRUE, sep = ",")
#remove NA values
daten <- daten |>
  tidyr::drop_na()
```


For the following stepwise forward regression performed, these predictors may suit best: 
- CO2_F_MDS because the more CO2 is available in the ais, the more CO2 can be taken up by photosynthesis.
- TA because the ideal temperature for plants destinctions their prodcutivity and the amount of CO2 taken up by photosynthesis.
- P because the more it rains, the more plants grow and the more CO2 can be taken up by photosynthesis.
- PPFD_IN because the amount of the photons destinct the process of photosynthesis.
- SW_IN because it is needed for the process of photosynthesis.
- LW_IN because it influences the process of photosynthesis but not as much as SW_IN does.


#Setting the number of predictors considered to p=1 and computing of their coefficient of determination
```{r}
#Predictor 1 (CO2_F_MDS)
model1 <- lm(GPP_NT_VUT_REF ~ CO2_F_MDS, data = daten)
summary(model1)$r.squared
plot(GPP_NT_VUT_REF ~ CO2_F_MDS, data = daten)
abline(model1, col = "red4")

#Predictor 2 (TA_F_MDS)
model2 <- lm(GPP_NT_VUT_REF ~ TA_F_MDS, data = daten)
summary(model2)$r.squared
plot(GPP_NT_VUT_REF ~ TA_F_MDS, data = daten)
abline(model2, col = "red4")

#Predictor 3 (P_F)
model3 <- lm(GPP_NT_VUT_REF ~ P_F, data = daten)
summary(model3)$r.squared
plot(GPP_NT_VUT_REF ~ P_F, data = daten)
abline(model3, col = "red4")

#Predictor 4 (PPFD_IN)
model4 <- lm(GPP_NT_VUT_REF ~ PPFD_IN, data = daten)
summary(model4)$r.squared
plot(GPP_NT_VUT_REF ~ PPFD_IN, data = daten)
abline(model4, col = "red4")

#Predictor 5 (SW_IN_F_MDS)
model5 <- lm(GPP_NT_VUT_REF ~ SW_IN_F_MDS, data = daten)
summary(model5)$r.squared
plot(GPP_NT_VUT_REF ~ SW_IN_F_MDS, data = daten)
abline(model5, col = "red4")

#Predictor 6 (LW_IN_F_MDS)
model6 <- lm(GPP_NT_VUT_REF ~ LW_IN_F_MDS, data = daten)
summary(model6)$r.squared
plot(GPP_NT_VUT_REF ~ LW_IN_F_MDS, data = daten)
abline(model6, col = "red4")
```


Regarding all of the calculated coefficient of determination of the different predictor models, the model 4 shows an coefficient of about 0.3627837. Thus, the computation of the AIC is done with model 4.

```{r}
aic_model4 <- AIC(model4)
aic_model4
```

The AIC of the predictor 4 is 45682.99 which relates to a poor adjustment to the data. The predicted values will probably not be accurate. As this result is not appropriate enough, the AIC for the other predictors is calculated and provides the following results:

```{r}
aic_model1 <- AIC(model1)
cat("AIC of model 1: ",aic_model1, "\n")

aic_model2 <- AIC(model2)
cat("AIC of model 2: ", aic_model2, "\n")

aic_model3 <- AIC(model3)
cat("AIC of model 3: ", aic_model3, "\n")

cat("AIC of model 4: ", aic_model4, "\n")

aic_model5 <- AIC(model5)
cat("AIC of model 5: ", aic_model5, "\n")

aic_model6 <- AIC(model6)
cat("AIC of model 6: ", aic_model6)
```

Considering the values of the calculated AIC's, the model 4 provides the most suitable value of about 45682.99 becauses it is the lowest one. According to this result, further steps will be done for the predictor 4.

To identify the best predictor in the model, it is better to use the stepwise forward regression. In the present case this is done as follows:

```{r}
library(tidyverse)
library(caret)
library(dplyr)
library(MASS)

#doing the stepwise regression
model_sfr <- lm(GPP_NT_VUT_REF ~ 1, data = daten)

final_model <- stepAIC(model_sfr, direction = "forward",
                      scope = list(upper = ~ TA_F_MDS + SW_IN_F_MDS + LW_IN_F_MDS + VPD_F_MDS + CO2_F_MDS + PPFD_IN),
                      data = daten)
summary(final_model)$r.squared

AIC(final_model)

```

Regarding the output of the computation, we assume that all of the predictors influence the GPP-value because every t-value of the predictors is lower than 0.05. If every predictor would be set to 0, we realise that the GPP will be -1.6149567. Furthermore, the multiple-R-squared value is 0.5026 which means that approx. 50.23% of the variation has to be influenced by coincidence. 

To get a more complex model of the data, one can add a new predictor:

```{r}
#Predictor 1 (CO2_F_MDS)
model1.1 <- lm(GPP_NT_VUT_REF ~ CO2_F_MDS, data = daten)
summary(model1.1)$r.squared
plot(GPP_NT_VUT_REF ~ CO2_F_MDS, data = daten)
abline(model1.1, col = "red4")

#Predictor 2 (TA_F_MDS)
model2.2 <- lm(GPP_NT_VUT_REF ~ TA_F_MDS, data = daten)
summary(model2.2)$r.squared
plot(GPP_NT_VUT_REF ~ TA_F_MDS, data = daten)
abline(model2.2, col = "red4")

#Predictor 3 (P_F)
model3.3 <- lm(GPP_NT_VUT_REF ~ P_F, data = daten)
summary(model3.3)$r.squared
plot(GPP_NT_VUT_REF ~ P_F, data = daten)
abline(model3.3, col = "red4")

#Predictor 4 (PPFD_IN)
model4.4 <- lm(GPP_NT_VUT_REF ~ PPFD_IN, data = daten)
summary(model4.4)$r.squared
plot(GPP_NT_VUT_REF ~ PPFD_IN, data = daten)
abline(model4.4, col = "red4")

#Predictor 5 (SW_IN_F_MDS)
model5.5 <- lm(GPP_NT_VUT_REF ~ SW_IN_F_MDS, data = daten)
summary(model5.5)$r.squared
plot(GPP_NT_VUT_REF ~ SW_IN_F_MDS, data = daten)
abline(model5.5, col = "red4")

#Predictor 6 (LW_IN_F_MDS)
model6.6 <- lm(GPP_NT_VUT_REF ~ LW_IN_F_MDS, data = daten)
summary(model6.6)$r.squared
plot(GPP_NT_VUT_REF ~ LW_IN_F_MDS, data = daten)
abline(model6.6, col = "red4")

#Predictor 7 (USTAR)
model7.7 <- lm(GPP_NT_VUT_REF ~ USTAR, data = daten)
summary(model7.7)$r.squared
plot(GPP_NT_VUT_REF ~ USTAR, data = daten)
     abline(model7.7, col = "red4")
```

```{r}
aic_model1.1 <- AIC(model1.1)
cat("AIC of model 1.1: ",aic_model1.1, "\n")

aic_model2.2 <- AIC(model2.2)
cat("AIC of model 2.2: ", aic_model2.2, "\n")

aic_model3.3 <- AIC(model3.3)
cat("AIC of model 3.3: ", aic_model3.3, "\n")

aic_model4.4 <- AIC(model4.4)
cat("AIC of model 4.4: ", aic_model4.4, "\n")

aic_model5.5 <- AIC(model5.5)
cat("AIC of model 5.5: ", aic_model5.5, "\n")

aic_model6.6 <- AIC(model6.6)
cat("AIC of model 6.6: ", aic_model6.6, "\n")

aic_model7.7 <- AIC(model7.7)
cat("AIC of model 7.7: ", aic_model7.7, "\n")

cat("Minimum: ", min(c(aic_model1.1, aic_model2.2, aic_model3.3, aic_model4.4, aic_model5.5, aic_model6.6, aic_model7.7)))
```
As the AIC of the model 7.7 (predictor USTAR) is higher than the one of the model with p = 1 predictors, the model with p predictors is the optimal model.

```{r}
model_np <- lm(GPP_NT_VUT_REF ~ TA_F_MDS + SW_IN_F_MDS + LW_IN_F_MDS + VPD_F_MDS + CO2_F_MDS + PPFD_IN + USTAR , data = daten)
summary(model_np)$r.squared
```

